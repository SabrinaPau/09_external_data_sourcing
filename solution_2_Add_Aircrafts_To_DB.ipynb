{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16843084",
   "metadata": {},
   "source": [
    "<img src=\"images/Plane.jpeg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399333f",
   "metadata": {},
   "source": [
    "# Inserting external data sources into PostgreSQL - Aircrafts\n",
    "In the last jupyter notebook we learned how to import a csv file directly from the web into Python and write its data into our PostgreSQL database. In this notebook we're going apply similar steps, but this time we're going to add data about aircrafts to our database. Also, instead of importing the data directly from the web, we're going to save it to our local file storage since the files are stored in a zip file. This means we will be unpacking the zip file first, then bring the data into the right shape and format through subsetting, merging and cleaning and ultimately insert it into our PostgreSQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b63ee",
   "metadata": {},
   "source": [
    "## Downloading aircraft zip file from the web\n",
    "The aircraft data we're going to work with can be downloaded from the Federal Aviation Administration website. Check out this [link](https://www.faa.gov/licenses_certificates/aircraft_certification/aircraft_registry/releasable_aircraft_download/) to find a description of the data as well as links for downloading either the entire database or yearly data.  \n",
    "\n",
    "We will be downloading the entire database into a folder called data. The folder does not exist yet in the repository so our first task is to create it.  \n",
    "Next we're going to create the download url and set the download path to the data folder we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273faaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new folder in your repo called 'data'. You can use '!' to run terminal commands from your notebook.\n",
    "\n",
    "# Specifies path for saving file\n",
    "path ='data/' \n",
    "# Create the data folder\n",
    "# !mkdir {path}\n",
    "\n",
    "# add your path to .gitignore so that you do not upload data to github\n",
    "# !echo {path} >> .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create download URL\n",
    "zip_file = 'ReleasableAircraft.zip'\n",
    "url = f'https://registry.faa.gov/database/{zip_file}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b6e0c",
   "metadata": {},
   "source": [
    "In order to download the file, we need to import a package called <ins>requests</ins>. This library specialises in working with data from the web.  \n",
    "Complete the code below and import the requests package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db468f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requests package\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf203f2",
   "metadata": {},
   "source": [
    "Now it's time to download the Aircraft Registration Database and save it to our the previously set download path. Since we want to get the files from the web to our local file storage, we have to send a GET request.  \n",
    "Use the <ins>get()</ins> function and pass it the url we created earlier. In a second step we're writing the files to our local file storage.\n",
    "The file is ~60MB, so depending on your internet speed this might take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bdc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the database\n",
    "r = requests.get(url)\n",
    "\n",
    "# Save database to local file storage\n",
    "with open(path+zip_file, 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa090cf",
   "metadata": {},
   "source": [
    "To make sure the file was downloaded successfully, go to the data folder in this repository and check its content. The folder should have a file called ReleasableAircraft.zip.  \n",
    "\n",
    "The next steps are to unpack the zip file and load the necessary files into Python. Conveniently there is a package to make unpacking a zip file in python easy, it's called <ins>zipfile</ins>.  \n",
    "\n",
    "Complete the code below and import the zipfile package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85153ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import zipfile package\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a487c86",
   "metadata": {},
   "source": [
    "Now it's time to unpack the zip file. First, we're going to use the <ins>ZipFile()</ins> function and pass it  the path to the file as its first argument. As the second argument, in order to read an existing file, we pass it the parameter 'r'. To extract the ZipFile object we can either use the <ins>extract()</ins> function, to extract a single file, or the <ins>extractall()</ins> function, to extract all files from the archive.  \n",
    "\n",
    "Complete the code below and either extract all files or only the MASTER.txt, ACFTREF.txt and ardata.pdf file using the extract() or extractall() function respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff83a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip zip file using zipfile.ZipFile()\n",
    "data = zipfile.ZipFile(path+zip_file, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff48596",
   "metadata": {},
   "outputs": [],
   "source": [
    "members = ['MASTER.txt', 'ACFTREF.txt', 'ardata.pdf']\n",
    "\n",
    "for member in members:\n",
    "    data.extract(member, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f55ec0",
   "metadata": {},
   "source": [
    "We can use the file explorer in vs code to take a quick peak at the files we just extracted. In the Explorer expand the 'data' folder and click on the file MASTER.TXT to get a quick feel for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc968b",
   "metadata": {},
   "source": [
    "Good job! MASTER.txt contains comma separated values and lists all registered aircrafts, exactly what we need. \n",
    "Now that we have the necessary files it's time to load them into Python.\n",
    "One thing we notice in the file is there are some missing values that are filled with multiple spaces, we will have to deal with that when we load it into Python. Which is what we will do now!\n",
    "Complete the code below, import the MASTER.txt file and save it in a variable called master_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary package\n",
    "import pandas as pd\n",
    "\n",
    "# Read MASTER.txt file and assign to variable master\n",
    "master_df = pd.read_csv(path+'MASTER.txt')\n",
    "\n",
    "# Print first 5 rows\n",
    "master_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc66f6",
   "metadata": {},
   "source": [
    "Next, let's have a look at the column names.  \n",
    "Complete the code below and print all column names with their non-null counts and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78dc6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print master info\n",
    "master_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71afcc1",
   "metadata": {},
   "source": [
    "## EDA & data preparation\n",
    "In total we have 287554 rows across 35 columns, some null values (although none in the ID column) and a mix of object and integer data types (if you're numbers are slightly different, this is because the database is updated regularly with new aircraft). \n",
    "All column names are uppercase and separated by spaces. As analysts we already know that this is not a preferred format. So before we continue let's make all columns lowercase and replace the spaces with underscores.  \n",
    "Complete the code below and transform all column names from uppercase to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column names lowercase\n",
    "master_df.columns = [x.lower() for x in master_df.columns]\n",
    "\n",
    "# Print all column names\n",
    "master_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f079ab",
   "metadata": {},
   "source": [
    "Next, we're going to replace spaces with underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces with underscores\n",
    "master_df.columns = [x.replace(' ', '_') for x in master_df.columns]\n",
    "\n",
    "# Print all column names\n",
    "master_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaed73f5",
   "metadata": {},
   "source": [
    "Perfect, now that the column names are in a consistent and clean format we can move on to working with the data. Even though the MASTER.txt file has 33 columns, we're only going to need 3: \n",
    "1. n-number: the tail number of the aircraft\n",
    "2. mfr_mdl_code: the manufacturer model code\n",
    "3. year_mfr: the year the aircraft was manufactured\n",
    "\n",
    "Complete the code below, create a subset of the master data that only includes the above mentioned columns and reassign it to the master variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset with n-number, mfr_mdl_code and year_mfg columns\n",
    "master_df = master_df[['n-number', 'mfr_mdl_code', 'year_mfr']]\n",
    "\n",
    "# Print all column names\n",
    "master_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52047706",
   "metadata": {},
   "source": [
    "Let's clean up the column names a bit more.\n",
    "Complete the code below and rename the columns to: nnum, code and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to nnum, code and year\n",
    "master_df.rename(columns={'n-number': 'nnum', 'mfr_mdl_code': 'code', 'year_mfr': 'year'}, inplace=True)\n",
    "\n",
    "\n",
    "# Print all column names\n",
    "master_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31c05d",
   "metadata": {},
   "source": [
    "While we're at it, we should remove any leading and trailing whitespace in our nnum and code column.  \n",
    "Complete the code below and remove any whitespace from the nnum and code column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove whitespace from nnum column\n",
    "master_df.nnum = master_df.nnum.str.strip()\n",
    "\n",
    "# Remove whitespace from code column\n",
    "master_df.code = master_df.code.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6da219",
   "metadata": {},
   "source": [
    "Great job so far! Now we have a file that contains a list of all aircrafts, their manufacturer model code and the year it was manufactured. I agree, this is not a lot of information but we're also not done yet. We still haven't looked at the other file: ACFTREF.txt. This file consists of detailed information for each aircraft such as the number of engines, engine type, number of seats etc. Let's import it and have a look!  \n",
    "Complete the code below and import the ACFTREF.txt file. Save it in a variable called ref and print its first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfa40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ACFTREF.txt file and assign to variable ref\n",
    "ref = pd.read_csv(path+'ACFTREF.txt')\n",
    "\n",
    "# Print first 5 rows\n",
    "ref.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498139e",
   "metadata": {},
   "source": [
    "Just like we did before, let's have a look at the column names, null values and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print table info\n",
    "ref.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ae10d",
   "metadata": {},
   "source": [
    "This time we have 12 columns, no null values and a mix of object and integer data types. On top of that all column names are uppercase again, but this time they're seperated with a dash. So before we continue let's make all columns lowercase and replace the dashes with underscores.  \n",
    "Complete the code below and transform all column names from uppercase to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3071572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column names lowercase\n",
    "ref.columns = [x.lower() for x in ref.columns]\n",
    "\n",
    "# Print all column names\n",
    "ref.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3d511",
   "metadata": {},
   "source": [
    "Next, we're going to replace spaces with underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c8fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces with underscores\n",
    "ref.columns = [x.replace('-', '_') for x in ref.columns]\n",
    "\n",
    "# Print all column names\n",
    "ref.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5fd61",
   "metadata": {},
   "source": [
    "Now the column names are in a format that makes it a lot easier to work with the table. Next we're going to create a subset of the data since we won't be needing all the columns present in the table.\n",
    "Complete the code below and create a subset that only contains the following columns: \n",
    "1. code: aircraft manufacturer, model and series code\n",
    "2. mfr: name of the aircraft manufacturer\n",
    "3. model: name of the aircraft model and series\n",
    "4. type_acft: the id of the aircraft type\n",
    "5. type_eng: the id of the engine type\n",
    "6. no_eng: number of engines on the aircraft\n",
    "7. no_seats: maximum number of seats in the aircraft\n",
    "8. speed: the aircraft average cruising speed\n",
    "\n",
    "Complete the code below and create a subset of the ref data that only includes the above mentioned columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns to keep\n",
    "ref = ref[['code', 'mfr', 'model', 'type_acft', 'type_eng', 'no_eng', 'no_seats', 'speed']]\n",
    "\n",
    "# Print all column names\n",
    "ref.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7c0d8",
   "metadata": {},
   "source": [
    "Great, now we have a subset that only contains the columns we're interested in.  \n",
    "Next, we're going to combine our master and ref dataset on the code column.  \n",
    "Complete the code below and inner join the master and ref dataset on the code column.  \n",
    "Save the combined dataset in a new variable called 'all' and print the dataframe's info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35600841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join master and ref and assign to all\n",
    "all = pd.merge(master_df, ref, on='code')  # pd.merge performs inner join by default\n",
    "\n",
    "# Print info\n",
    "all.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77135d03",
   "metadata": {},
   "source": [
    "It worked, awesome! Now we have a combined dataset that consists of detailed aircraft information.  Unfortunately, we're not done yet. The two columns type_acft and type_eng only contain ids and no real information about aircraft and engine type. Fortunately, the Federal Aviation Administration includes a documentation file with the database. The file is called ardata.pdf and contains column descriptions as well as values for codes and ids.  \n",
    "\n",
    "Let's translate the type_eng column first. Looking into the documentation we find 12 different engine types with ids ranging from 0 to 11. First we should check whether we find these ids in the type_eng column.  \n",
    "Complete the code below and print a list of all distinct type_eng id values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print list of distinct type_eng ids\n",
    "display(all.type_eng.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f046c13",
   "metadata": {},
   "source": [
    "Good, the ids in the type_eng column match with the ones listed in the documentation.  \n",
    "Next, create a list of engine types, called engine_list, that includes all engine types listed in the documentation. Make sure to store them in the same order they are listed in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee0715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of engine type names: engine_list\n",
    "engine_list = [\"None\", \n",
    "          \"Reciprocating\", \n",
    "          \"Turbo-prop\", \n",
    "          \"Turbo-shaft\", \n",
    "          \"Turbo-jet\",\n",
    "          \"Turbo-fan\", \n",
    "          \"Ramjet\", \n",
    "          \"2 Cycle\", \n",
    "          \"4 Cycle\", \n",
    "          \"Unknown\", \n",
    "          \"Electric\", \n",
    "          \"Rotary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9cda89",
   "metadata": {},
   "source": [
    "Now we're going to add a new column called engine that has the engine name based on the id in type_eng. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74941d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add engine column and translate type_eng id\n",
    "all['engine'] = [engine_list[i] for i in all['type_eng'].tolist()]\n",
    "\n",
    "# Print first 5 rows\n",
    "all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a77af",
   "metadata": {},
   "source": [
    "Good job, that was certainly not an easy task. Now that we have the actual engine type names in our dataset we don't need the type_eng column anymore.  \n",
    "Complete the code below and delete the type_eng column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete type_eng column\n",
    "all.drop(columns=['type_eng'], inplace=True)\n",
    "\n",
    "# Print all column names\n",
    "all.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0328d8",
   "metadata": {},
   "source": [
    "Now that we know how to translate an id into its actual value, let's do the same for the type_acft column.  \n",
    "First, let's have a look at the documentation. There we find 11 engine types with ids ranging from 1 to 9 and two letters H and O. This complicates things, but before we look further into this let's check the type_afct column values for matching ids first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print list of distinct type_acft ids\n",
    "all.type_acft.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749fdcd",
   "metadata": {},
   "source": [
    "Again, the ids are matching, which is good news. The bad news is we have a mix of numerical ids and letters and because of the letters the column is in a string format. The approach we used with the type_eng column will not work with the current format of the column and ids. There is no reason to get demotivated though, this points us to a more efficient and secure way to fill data based on ids. First, let's create a dictionary to capture the ids and type names. Similar to before, use the documentation file to get the values and this time type them into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acft_dict= {\n",
    "            '1':'Glider',\n",
    "            '2':'Balloon',\n",
    "            '_':'Blimp/Dirigible',\n",
    "            '4':'Fixed wing single engine', \n",
    "            '5':'Fixed wing multi engine',\n",
    "            '6':'Rotorcraft',\n",
    "            '_':'Weight-shift-control',\n",
    "            '8':'Powered Parachute',\n",
    "            '9':'Gyroplane',\n",
    "            '_':'Hybrid Lift',\n",
    "            '_':'Other'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3fa9c",
   "metadata": {},
   "source": [
    "The last step is to translate the ids in the type_acft column into aircraft type names.  \n",
    "Complete the code below and add a new column called aircraft_type that consists of the correct aircraft type names based on the id in the type_acft column.\n",
    "With the help of the map-function, we can apply a transformation function to each item in an iterable and transform them into a new iterable. In our case, we transform the ids into names. This could be thought of as similar to VLOOKUP in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ab58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values in the aircraft_type column by mapping the keys from type_acft column to the values in the acft_dict dictionary.\n",
    "all['type_acft'] = all['type_acft'].map(acft_dict)\n",
    "\n",
    "# Print list of distinct aircraft types and aircraft ids found in our dataset and the corresponding number of records for each type.\n",
    "print(all[['type_acft', 'engine']].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f534c999",
   "metadata": {},
   "source": [
    "Good job, that was a tricky one! Now that we have the actual aircraft type names in our dataset we don't need the type_acft column anymore.  \n",
    "Complete the code below and delete the type_acft column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete type_acft column\n",
    "all.drop(columns=['type_acft'], inplace=True)\n",
    "\n",
    "# Print all column names\n",
    "all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566628e1",
   "metadata": {},
   "source": [
    "Done! We successfully translated the ids to their actual values. Before we write the table into our database, let's make sure we have clean and descriptive column names. The first column we are going to change is the nnum column. Lets have a look at its values before we rename it.  \n",
    "Complete the code below and print the first 5 rows of the nnum column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 5 rows of nnum column\n",
    "all.nnum.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08bba3f",
   "metadata": {},
   "source": [
    "Something is weird. Aren't the tail numbers in our flights data starting with the letter 'N'? Let's check that just to be sure. In order to do this we need to connect to our database and query the unique tail numbers from the flights table. In order to create a connection we need to create a connection to the PostgreSQL database. We stored a function for this in the sql.py file already. All that's left to do is import our get_data function from the sql.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f870b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import get_data from sql_functions.py\n",
    "from sql_functions import get_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f97fd",
   "metadata": {},
   "source": [
    "Next, query the distinct tail numbers from the flights table and store them in a variable f_planes and print the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aab645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store unique tail numbers in f_planes\n",
    "f_planes = get_dataframe('SELECT DISTINCT tail_number FROM hh_analytics_22_2.flights')\n",
    "\n",
    "# Print first 5 rows of f_planes\n",
    "f_planes.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f45a83",
   "metadata": {},
   "source": [
    "Indeed, the tail numbers all start with the letter 'N'. To make sure the nnum column really consists of tail numbers and only the letter 'N' is missing, let's calculate how many matching values we have between the two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45a5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count matching values in tail_number and nnum\n",
    "# all['nnum'].isin(f_planes['tail_number'].str[1:]).value_counts()\n",
    "f_planes['tail_number'].str[1:].isin(all['nnum']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a013797",
   "metadata": {},
   "source": [
    "We have 4506 matches (or something similar since the live data changes), which is quite a significant number. Therefore, we can assume that in order to match the nnum and the tail_number column, all we need to do is add the letter 'N' in front of each value in the nnum column.  \n",
    "Complete the code below and create a new column in all called tail_number that consists of the letter 'N' and the nnum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde39849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tailnum column\n",
    "all['tail_number'] = all['nnum'].apply(lambda x: ('N' + str(x)))\n",
    "\n",
    "# Print first 5 rows\n",
    "all.tail_number.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69e8ab",
   "metadata": {},
   "source": [
    "There we go! Now we have a tail number column that we can join with our flights table later on. Let's change the order of the columns and get rid of the code column since we don't need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d031ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove code column, change column order and assign to planes\n",
    "planes = all[['tail_number', 'year', 'mfr', 'model', 'engine', 'no_eng', 'no_seats', 'speed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6ce71",
   "metadata": {},
   "source": [
    "As a final data cleaning step give the mfr, no_eng and no_seats column a more descriptive name.  \n",
    "Complete the code below and change the column names mfr into manufacturer, no_eng into engines and no_seats into seats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20657dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names\n",
    "planes.rename(columns={'mfr' : 'manufacturer', 'no_eng' : 'engines', 'no_seats' : 'seats'}, inplace=True)\n",
    "\n",
    "# Print all column names\n",
    "planes.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c280da23",
   "metadata": {},
   "source": [
    "Awesome! We finally have a clean dataset with detailed information about aircrafts. Let's check how many unique aircrafts we have in our dataset.  \n",
    "Complete the code below and count the unique airplanes in the planes variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6364d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique aircrafts\n",
    "planes.tail_number.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17320d3",
   "metadata": {},
   "source": [
    "Wow, almost 290k aircrafts. Previously when we counted the matches between the nnum columnd and tail_number column we only had 4506 matches, which is a lot less than we have from the official source. Since we only need a small subset, let's filter out the remaining ones.  \n",
    "Complete the code below and create a dataframe called final_table that has all aircrafts from the planes dataset that have matches in the f_planes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ca0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with only matching values called final_table\n",
    "final_table = planes.merge(f_planes, how='inner', on='tail_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4712e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print count of planes in final_table\n",
    "final_table.tail_number.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590934d3",
   "metadata": {},
   "source": [
    "Good job! Instead of a huge dataset with all aircrafts we now have a smaller subset that matches the aircrafts we have in our flights table in our PostregSQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e2d8b",
   "metadata": {},
   "source": [
    "## Inserting aircrafts data into the database\n",
    "The last step is to write this table into our database. We already learned how to do this using the sql.py file. The credentials should be filled out since we've already done that in the previous notebook.  \n",
    "Make sure the credentials a set up correctly and import the engine from the sql.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import get_engine function from sql_functions.py and set it to a variable called engine\n",
    "from sql_functions import get_engine\n",
    "engine = get_engine()\n",
    "\n",
    "# Import psycopg2\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e931c",
   "metadata": {},
   "source": [
    "Next, set the table name variable. This will be name of the table that will be written to the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96fecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Set the schema to your course name and set the table_name variable to 'planes_' + your initials/group number\n",
    "# Example: planes_pw for Philipp Wendt / planes_1 for group1\n",
    "schema = 'hh_analytics_22_2' # example 'hh_analytics_22_1\n",
    "table_name = 'planes_###'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836afb1d",
   "metadata": {},
   "source": [
    "The final step is to write the dataset to the database.  \n",
    "Complete the code below and write the dataset stored in planes_in_both to the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb17e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        final_table.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        schema=schema, # your class schema\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "    print('No engine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d4771",
   "metadata": {},
   "source": [
    "To check if everything worked try querying the table from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed31730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the new planes table to get number of planes in the SQL table\n",
    "get_dataframe(f'select * from {schema}.{table_name}').tail_number.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eeb5d0",
   "metadata": {},
   "source": [
    "You made it, congratulations!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c96e12ea435425e5eacdf5151fc2e31f65462d718b52a4ac07f3a4743bbc86b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('sql-practice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
