{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"images/Plane.jpeg\" width=\"800\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inserting external data sources into PostgreSQL - Aircrafts\n",
    "In the last jupyter notebook we learned how to import a csv file directly from the web into Python and write its data into our PostgreSQL database. In this notebook we're going apply similar steps, but this time we're going to add data about aircrafts to our database. Also, instead of importing the data directly from the web, we're going to save it to our local file storage since the files are stored in a zip file. This means we will be unpacking the zip file first, then bring the data into the right shape and format through subsetting, merging and cleaning and ultimately insert it into our PostgreSQL database.  \n",
    "\n",
    "The aircraft data we're going to work with can be downloaded from the Federal Aviation Administration website. Check out this [link](https://www.faa.gov/licenses_certificates/aircraft_certification/aircraft_registry/releasable_aircraft_download/) to find a description of the data as well as links for downloading either the entire database or yearly data.  \n",
    "\n",
    "For our use case, we will be downloading the entire database. To do this, we need to import a package that we have worked with previously and is perfect for getting data from the web.  \n",
    "Complete the code below and import the necessary package."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import package\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we're going to create the download url and set the download path."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create download URL\n",
    "zip_file = f'ReleasableAircraft.zip'\n",
    "url = f'https://registry.faa.gov/database/{zip_file}'\n",
    "\n",
    "# Set download path\n",
    "path ='data/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it's time to download the Aircraft Registration Database and save it to our the previoulsy set download path.  \n",
    "The file is ~60MB, so depending on your internet speed this might take a few seconds."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Download the database\n",
    "r = requests.___(___)\n",
    "\n",
    "# Save database to local file storage\n",
    "with open(path+zip_file, 'wb') as f:\n",
    "    f.write(r.content)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To make sure the file was downloaded successfully, go to the data folder in this repository and check its content. The folder should have a file called ReleasableAircraft.zip.  \n",
    "\n",
    "The next steps are to unpack the zip file and load the necessary files into Python. Conveniently there is a package to make unpacking a zip file in paython easy, it's called <ins>zipfile</ins>.  \n",
    "\n",
    "Complete the code below and import the zipfile package."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import zipfile package\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now it's time to unpack the zip file. First, we're going to use the <ins>ZipFile()</ins> function and pass it  the path to the file as its first argument. As the second argument, in order to read an existing file, we pass it the parameter 'r'. To extract the ZipFile object we can either use the <ins>extract()</ins> function, to extract a single file, or the <ins>extractall()</ins> function, to extract all files from the archive.  \n",
    "\n",
    "Complete the code below and either extract all files or only the MASTER.txt, ACFTREF.txt and ardata.pdf file using the extract() or extractall() function respectively."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Unzip zip file\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Good job! Now that we have the necessary files it's time to load them into Python. The MASTER.txt contains all registered aircrafts, exactly what we need.  \n",
    "Complete the code below, import the MASTER.txt file and save it in a variable called master."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import the necessary package\n",
    "\n",
    "\n",
    "# Read MASTER.txt file and assign to variable master\n",
    "\n",
    "\n",
    "# Print first 5 rows\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, let's have a look at the column names.  \n",
    "Complete the code below and print all column names with their non-null counts and data types."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print master info\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In total we have 287554 rows across 33 columns, no null values and a mix of object and integer data types. On top of that all column names are uppercase and seperated by spaces. As analysts we already know that this is not a preferred format. So before we continue let's make all columns lowercase and replace the spaces with underscores.  \n",
    "Complete the code below and transform all column names from uppercase to lowercase."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Make column names lowercase\n",
    "\n",
    "\n",
    "# Print all column names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we're going to replace spaces with underscores."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Replace spaces with underscores\n",
    "\n",
    "\n",
    "# Print all column names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perfect, now that the column names are in a consistent and clean format we can move on to working with the data. Even though the MASTER.txt file has 33 columns, we're only going to need 3: \n",
    "1. n-number: the tail number of the aircraft\n",
    "2. mfr_mdl_code: the manufacturer model code\n",
    "3. year_mfr: the year the aircraft was manufactured\n",
    "\n",
    "Complete the code below, create a subset of the master data that only includes the above mentioned columns adn reassign it to the master variable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create subset with n-number, mfr_mdl_code and year_mfg columns\n",
    "\n",
    "\n",
    "# Print all column names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's clean up the column names a bit more.\n",
    "Complete the code below and rename the columns to: nnum, code and year."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Rename columns to nnum, code and year\n",
    "\n",
    "\n",
    "# Print all column names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "While we're at it, we should remove any leading and trailing whitespace in our nnum and code column.  \n",
    "Complete the code below and remove any whitepsace from the nnum and code column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove whitespace from nnum column\n",
    "\n",
    "\n",
    "# Remove whitespace from code column\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great job so far! Now we have a file that contains a list of all aircrafts, their manufacturer model code and the year it was manufactured. I agree, this is not a lot of information but we're also not done yet. We still haven't looked at the other file: ACFTREF.txt. This file consists of detailed information for each aircraft such as the number of engines, engine type, number of seats etc. Let's import it and have a look!  \n",
    "Complete the code below and import the ACFTREF.txt file. Save it in a variable called ref and print its first 5 rows."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read ACFTREF.txt file and assign to variable ref\n",
    "\n",
    "\n",
    "# Print first 5 rows\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just like we did before, let's have a look at the column names, null values and data types."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print table info\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This time we have 12 columns, no null values and a mix of object and integer data types. On top of that all column names are uppercase again, but this time they're seperated with a dash. So before we continue let's make all columns lowercase and replace the dashes with underscores.  \n",
    "Complete the code below and transform all column names from uppercase to lowercase."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Make column names lowercase\n",
    "\n",
    "\n",
    "# Print all column names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we're going to replace spaces with underscores."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Replace spaces with underscores\n",
    "\n",
    "\n",
    "# Print all column names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the column names are in a format that makes it a lot easier to work with the table. Next we're going to create a subset of the data since we won't be needing all the columns present in the table.\n",
    "Complete the code below and create a subset that only contains the following columns: \n",
    "1. code: aircraft manufacturer, model and series code\n",
    "2. mfr: name of the aircraft manufacturer\n",
    "3. model: name of the aircraft model and series\n",
    "4. type_acft: the id of the aircraft type\n",
    "5. type_eng: the id of the engine type\n",
    "6. no_eng: number of engines on the aircraft\n",
    "7. no_seats: maximum number of seats in the aircraft\n",
    "8. speed: the aircraft average cruising speed\n",
    "\n",
    "Complete the code below and create a subset of the ref data that only includes the above mentioned columns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Select columns to keep\n",
    "\n",
    "\n",
    "# Print all column names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great, now we have a subset that only contains the columns we're interested in.  \n",
    "Next, we're going to combine our master and ref dataset on the code column.  \n",
    "Complete the code below and inner join the master and ref dataset on the code column.  \n",
    "Save the combined dataset in a new variable called 'all' and print the dataframe's info."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Inner join master and ref and assign to all\n",
    "\n",
    "\n",
    "# Print info\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It worked, awesome! Now we have a combined dataset that consists of detailed aircraft information.  Unfortunately, we're not done yet. The two columns type_acft and type_eng only contain ids and no real information about aircraft and engine type. Fortunately, the Federal Aviation Administration includes a documentation file with the database. The file is called ardata.pdf and contains column descriptions as well as values for codes and ids.  \n",
    "\n",
    "Let's translate the type_eng column first. Looking into the documentation we find 12 different engine types with ids ranging from 0 to 11. First we should check whether we find these ids in the type_eng column.  \n",
    "Complete the code below and print a list of all distinct type_eng id values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print list of distinct type_eng ids\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Good, the ids in the type_eng column match with the ones listed in the documentation.  \n",
    "Next, create a list of engine types, called engine, that includes all engine types listed in the documentation. Make sure to store them in the same order they are listed in the documentation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create list of engine type names: engine\n",
    "engine = [\"None\", \n",
    "          \"___________\", \n",
    "          \"Turbo-prop\", \n",
    "          \"Turbo-shaft\", \n",
    "          \"__________\",\n",
    "          \"Turbo-fan\", \n",
    "          \"Ramjet\", \n",
    "          \"2 Cycle\", \n",
    "          \"4 Cycle\", \n",
    "          \"Unknown\", \n",
    "          \"_________\", \n",
    "          \"Rotary\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we're going to add a new column called engine that has the engine name based on the id in type_eng. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add engine column and translate type_eng id\n",
    "all['______'] = [engine[i] for i in all['_______'].tolist()]\n",
    "\n",
    "# Print first 5 rows\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Good job, that was certainly not an easy task. Now that we have the actual engine type names in our dataset we don't need the type_eng column anymore.  \n",
    "Complete the code below and delete the type_eng column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Delete type_eng column\n",
    "\n",
    "\n",
    "# Print all column names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we know how to translate an id into its actual value, let's do the same for the type_acft column.  \n",
    "First, let's have a look at the documentation. There we find 11 engine types with ids ranging from 1 to 9 and two letters H and O. This complicates things, but before we look further into this let's check the type_afct column values for matching ids first."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print list of distinct type_acft ids\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, the ids are matching, which is good news. The bad news is we have a mix of numerical ids and letters and because of the letters the column is in a string format. The approach we used with the type_eng column will not work with the current format of the column and ids. There is no reason to get demotivated though, this is only but a small hurdle we have to overcome. First, let's change the H and O id in the type_acft column into the numerical ids 10 and 11.  \n",
    "Complete the code below and replace all H values with the number 10 and all O values with the number 11."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Replace H with 10 and O with 11\n",
    "\n",
    "\n",
    "\n",
    "# Print list of distinct type_eng ids\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now even though all ids are numerical values they are still strings due to the column type being string. We can resolve this by changing the column type to numerical.  \n",
    "Complete the code below and transform the type_acft column to numerical."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert type_acft column to numerical\n",
    "\n",
    "\n",
    "# Print data type of type_acft column\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Good job! Now we have consistent and clean type_acft values. Let's move on and just like before create a list called acft and store all aircraft types from the documentation in it. Make sure to store them in the same order they are listed in the documentation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "acft = [\"Glider\", \n",
    "        \"_______\", \n",
    "        \"Blimp/Dirigible\", \n",
    "        \"Fixed wing single engine\",\n",
    "        \"Fixed wing multi engine\", \n",
    "        \"_________\", \n",
    "        \"Weight-shift-control\",\n",
    "        \"Powered Parachute\", \n",
    "        \"_________\",\n",
    "        'Hybrid Lift',\n",
    "        'Other']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last step is to translate the ids in the type_acft column into engine type names.  \n",
    "Complete the code below and add a new column called type that consists of the correct aircraft type names based on the id in the type_acft column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add aircraft type and delete type-acft column\n",
    "all['_____'] = [acft[____] for i in all['_______'].tolist()]\n",
    "\n",
    "# Print first 5 rows\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Good job, that was a tricky one! Now that we have the actual aircraft type names in our dataset we don't need the type_acft column anymore.  \n",
    "Complete the code below and delete the type_acft column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Delete type_acft column\n",
    "\n",
    "\n",
    "# Print all column names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Done! We successfully translated the ids to their actual values. Before we write the table into our database, let's make sure we have clean and descriptive column names. The first column we are going to change is the nnum column. Lets have a look at its values before we rename it.  \n",
    "Complete the code below and print the first 5 rows of the nnum column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print first 5 rows of nnum column\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Something is weird. Aren't the tail numbers in our flights data starting with the letter 'N'? Let's check that just to be sure. In order to do this we need to connect to our database and query the unique tail numbers from the flights table. In order to create a connection we need to create a connection object using the connect() function in combination with the credentails for the PostgreSQL database. We stored this in the sql.py file already. All that's left to do is to enter the credentials and import he connection object conn into this notebook.\n",
    "Fill in the credentials in the sql.py file, complete the code below and import the conn object from the sql.py file."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import conn from sql.py\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, query the distinct tail numbers from the flights table and store them in a variable f_planes and print the first 5 rows."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Store unique tail numbers in f_planes\n",
    "\n",
    "\n",
    "# Print first 5 rows of f_planes\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Indeed, the tail numbers all start with the letter 'N'. To make sure the nnum column really consists of tail numbers and only the letter 'N' is missing, let's calculate how many matching values we have between the two columns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Count matching values in tail_number and nnum\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have 4506 matches, which is quite a significant number. Therefore, we can assume that in order to match the nnum and the tail_number column, all we need to do is add the letter 'N' in front of each value in the nnum column.  \n",
    "Complete the code below and create a new column in all called tail_number that consists of the letter 'N' and the nnum values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create tailnum column\n",
    "\n",
    "\n",
    "# Print first 5 rows\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There we go! Now we have a tail number column that we can join with our flights table later on. Let's change the order of the columns and get rid of the code column since we don't need it anymore."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove code column, change column order and assign to planes\n",
    "planes = all[['tail_number', 'year', 'type', 'mfr', 'model', 'engine', 'no_eng', 'no_seats', 'speed']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a final data cleaning step give the mfr, no_eng and no_seats column a more descriptive name.  \n",
    "Complete the code below and change the column names mfr into manufacturer, no_eng into engines and no_seats into seats."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Change column names\n",
    "planes.rename(columns={'___' : '_____', '_____' : '______', '_____' : '_____'}, inplace=True)\n",
    "\n",
    "# Print all column names\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Awesome! We finally have a clean dataset with detailed information about aircrafts. Let's check how many unique aircrafts we have in our dataset.  \n",
    "Complete the code below and count the unique airplanes in the planes variable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Count unique aircrafts\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wow, almost 290k aircrafts. Previously when we counted the matches between the nnum columnd and tail_number column we only had 4506 matches, which is a lot less than we have from the official source. Since we only need a small subset, let's filter out the remaining ones.  \n",
    "Complete the code below and create a dataframe called semi_table that has all aircrafts from the planes dataset that have matches in the f_planes dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create dataframe with matching values: semi_table\n",
    "semi_table = planes.merge(f_planes, how='inner', on='tail_number')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we need to use the list of tail numbers from the semi_table dataset to filter our planes dataset.  \n",
    "Complete the code below and create a variable in_both that returns TRUE for each tail number from the semi_table that can be found in the tail_number column from the planes dataset and FALSE whenever there is not match."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a series of bool values: in_both\n",
    "in_both = planes['_________'].isin(_____________)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What's left is to filter the planes dataset based on the boolean values in the in_both variable.  \n",
    "Complete the code below and create a new variable called planes_in_both that consists of the planes dataset filtered by the in_both variable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Filter planes and store in planes_in_both\n",
    "planes_in_both = ____________\n",
    "\n",
    "# Print planes_in_both\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Good job! Instead of a huge dataset with all aircrafts we now have a smaller subset that matches the aircrafts we have in our flights table in our PostregSQL database.  \n",
    "\n",
    "The last step is to write this table into our database. We already learned how to do this using the sql.py file. The credentials should be filled out since we've already done that in the 'From Web to DB' session.  \n",
    "Make sure the credentials a set up correctly in the sql.py file and import the engine from the sql.py file.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import engine from sql.py\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, set the table name variable. This will be name of the table that will be written to the PostgreSQL database."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# IMPORTANT: Set the table_name variable to 'planes_' + your initials/group number\n",
    "# Example: planes_pw for Philipp Wendt / planes_1 for group1\n",
    "table_name = '_________'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The final step is to write the dataset to the database.  \n",
    "Complete the code below and write the dataset stored in planes_in_both to the PostgreSQL database."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        carriers.to_sql(___________, # Name of SQL table\n",
    "                        con=_______, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To check if everything worked try querying the table from the database."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Query the new planes table\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You made it, congratulations!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('sql-practice': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "3dbd66691e1f512e55fbf3dc67ae6d2a739f4e865244fb8280a44333b8dc0ac7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}